#!/bin/python3

import argparse
import os.path
import math
import random

# List containing the possible classifications in the system.

classes = []

# List containing the possible entries of a data field in the dataset.

attributes = []

# Dictionary of flags to modify behaviour

flags = { 'use_continuous' : False,
          'use_missing_data' : False,
          'prune_tree' : False }
args = {}
training_set = []
testing_set = []
rules = []
output_file = open("dat.out","w")

# Helper function to print an error message and exit the program.

def fatalError(msg):
    print("Error: " + msg)
    os._exit(0)

# Function that will extract an array from a string with items in
# "{ item, item, item, ..., item  }"
# format

def extract_array(input):
    input = input.replace('{','')
    input = input.replace('}','')
    array = list(map(lambda x : x.strip(), input.strip().split(",")))
    return array

# Manages the parsing of command line arguments and populating the
# correct flags as per those given arguments.

def parse_args():
    global args
    parser = argparse.ArgumentParser()
    parser.add_argument("-d", help="Use only discrete values.",
                        action="store_true")

    parser.add_argument("-c", help="Use both continuous and discrete values.",
                        action="store_true")

    parser.add_argument("-md", help="Use only discrete values, permit missing "
                        + "information.", action="store_true")

    parser.add_argument("-mc", help="Use continuous and discrete values, "
                        + "permit missing information.", action="store_true")

    parser.add_argument("-pd", help="Use only discreet values, prune decision "
                        + "tree.", action="store_true")

    parser.add_argument("-pc", help="Use continuous and discrete values, prune"
                        + " decision tree.", action="store_true")

    parser.add_argument("spec")
    parser.add_argument("dat")
    args = parser.parse_args()

    # Set program flags for behaviour

    if args.c or args.mc or args.pc:
        flags['use_continuous'] = True
    if args.md or args.mc:
        flags['use_missing_data'] = True
    if args.pd or args.pc:
        flags['prune_tree'] = True

# Populates attributes from the .spec file

def parse_spec_file(file_name):
    global classes
    if os.path.exists(file_name):
        file = open(file_name,  "r")
        read_classname = False;
        for line in file:
            line_array = list(map(lambda x : x.strip(), line.strip().split(":")))
            if not read_classname:
                classes = line_array[1].split(" ")
                read_classname = True
            else:
                new_attrib = {}
                new_attrib["name"] = line_array[0]
                if line_array[1] == 'Real':
                    if flags['use_continuous']:
                        new_attrib["Type"] = line_array[1]
                    else:
                        fatalError("Continuous attribute found. Please run with a flag that permits continuous data.")
                else :
                    new_attrib["Type"] = extract_array(line_array[1])
                attributes.append(new_attrib)
        file.close()
    else:
        fatalError("Specification file not found!")

# Adds an entry to the training set from a line in the data file.
# Checks for correct input, and converts to a real number where appropriate.

def add_entry(line):
    line = line.strip()
    line_array = list(map(lambda x : x.strip(), line.split(" ")))
    new_entry = {}
    for x in range(0,len(attributes)):
        if line_array[x] == '?':
            if flags['use_missing_data']:
                new_entry[attributes[x]['name']] = None;
            else:
                fatalError("Missing data encountered. Please run with a flag that permits missing data.")
        elif attributes[x]['Type'] == 'Real':
            new_entry[attributes[x]['name']] = int(line_array[x])
        else:
            new_entry[attributes[x]['name']] = line_array[x]
            if line_array[x] not in attributes[x]['Type']:
                fatalError("Unexpected value \"" + line_array[x] + "\" for field " + attributes[x]['name']
                           + " in data file. Expected " + str(attributes[x]['Type']))    	
    new_entry['class'] = line_array[-1]
    training_set.append(new_entry)

def parse_data_file(file_name):
    if os.path.exists(file_name):
        file = open(file_name,  "r")
        for line in file:
            add_entry(line)
        file.close()
    else:
        fatalError("Data file not found!")

# Splits training set and testing set 70 / 30

def partition_sets():
    global training_set
    global testing_set
    random.shuffle(training_set)
    length = len(training_set)
    testing_set = training_set[:int(0.3*length)]
    training_set = training_set[int(0.3*length):]

# Returns a subset of the input set, where all the entries have
# the value `test_value` for attribute `test_attribute`

def subset(input_set, test_attribute, test_value):
    new_set = []
    for entry in input_set:
       if entry[test_attribute] == test_value:
           new_set.append(entry)
    return new_set

# Function to calculate the entropy of a set where

def entropy(num_true, total):
    if num_true == 0 or total == 0:
        return -0
    return num_true/total * math.log(num_true/total,2)

def entropy_of_set(input_set):
    if len(input_set) == 0:
        return 0
    entropy_total = 0
    class_totals = {}

    # set counters of classes to zero
    for entry_class in classes:
        class_totals[entry_class] = 0
    for entry in input_set:
        for entry_class in classes:
          if entry['class'] == entry_class:
             class_totals[entry_class] += 1
     
    # calculate the net entropy by summing over the entropy of the classes    

    for entry_class in classes:
        entropy_total += entropy(class_totals[entry_class], len(input_set))
    entropy_total = abs(entropy_total)
    return entropy_total

def probability_of_missing(input_set, attribute):
    missing_count = 0
    for entry in input_set:
        if entry[attribute["name"]] == None:
           missing_count += 1
    return missing_count / len(input_set) 

def frequency(input_set, attribute, value):
    count = 0
    for entry in input_set:
        if entry[attribute] == value:
            count += 1
    return count / len(input_set)

def average_entropy(input_set, attribute):
    total = 0
    for value in attribute["Type"]:
         total += frequency(input_set, attribute["name"], value) * entropy_of_set(subset(input_set, attribute["name"],value))  
    return total

# Function that calculates the gain of partitioning a set
# with criterion test.

def gain(input_set, attribute): 
    return (1-probability_of_missing(input_set, attribute))*(entropy_of_set(input_set) - average_entropy(input_set, attribute))

# Splits an input set into subsets based on value

def split_set(input_set, attribute):
    set_array = []
    sets = {}
    if attribute == None:
        return
    for value in attribute["Type"]:
        sets[value] = []

    # For every entry in the set. If the entries attribute is not none,
    # add it to the set of those attributes, otherwise propogate to all sets.

    for entry in input_set:
        if entry[attribute["name"]] != None:
            sets[entry[attribute["name"]]].append(entry)
        else:
            augmented_entry = entry
            for key in sets.keys():
                augmented_entry[attribute["name"]] = key
                sets[key].append(augmented_entry)

    for value in attribute["Type"]:
        set_array.append(sets[value])
    return set_array

def parts_from_splits(splits):
    parts = []
    for entry in splits:
        line_array = entry.split(" = ")
        parts.append((line_array[0], line_array[1]))
    return parts

def attribute_value(input_set, attribute):
    for entry in input_set:
        if entry[attribute["name"]] != None:
            return entry[attribute["name"]]
    return None

# Function that checks whether a set has any difference other than classifications

def induceable(input_set):
    for attribute in attributes:
        attribute_value = None
        for entry in input_set:
            if attribute_value == None:
                attribute_value = entry[attribute["name"]]
            else:
                if entry[attribute["name"]] != attribute_value:
                    return True
    return False

# Function that encapsulates the main logic of constructing the decision tree.
# Will need to add some recursive component

def induce(input_set, splits_performed=None, forbidden_attributes=None):
    if len(input_set) == 0:
        return
    
    set_entropy = entropy_of_set(input_set)
    # if the set is not homogenous

    max_gain_attribute = attributes[0]
    max_gain = -1
    forbidden_attributes = [] if forbidden_attributes == None else forbidden_attributes[:]

    if set_entropy != 0.0:
        if not induceable(input_set):
            return

        for attribute in attributes:
            if attribute["name"] not in forbidden_attributes:
                attribute_gain = gain(input_set, attribute)
                if attribute_gain > max_gain:
                    max_gain = attribute_gain
                    max_gain_attribute = attribute
        children_sets = split_set(input_set, max_gain_attribute)
        forbidden_attributes.append(max_gain_attribute["name"])
        for child in children_sets:
            if len(child) > 0:
                child_splits_performed = [] if splits_performed == None else splits_performed[:]
                child_splits_performed.append(max_gain_attribute["name"] + " = " + attribute_value(child,max_gain_attribute))
                induce(child,child_splits_performed, forbidden_attributes)
    else:
        if splits_performed != None and len(splits_performed) > 0:
            output_string = "IF "
            for x in range(0,len(splits_performed)):
                output_string += "(" + splits_performed[x] + ")"
                if x < len(splits_performed) - 1:
                   output_string += " AND "
                rule = {}
                rule["class"] = input_set[0]["class"]
                rule["parts"] = parts_from_splits(splits_performed)
                if rule not in rules:
                    rules.append(rule)
            output_string += " THEN\n"
            output_string += "  CLASS IS " + input_set[0]["class"] + "\n\n"
            output_file.write(output_string)

def has_missing_data(entry):
    for key in entry.keys():
        if entry[key] == None:
            return True
    return False

def max_class(classes):
    if (len(classes) == 1):
        return classes[0]
    max = -1
    st = set(classes)
    mx = -1
    h = None
    for each in st:
        temp = classes.count(each)
        if mx < temp:
            mx = temp
            h = each
    return h 

def classify(entry, using_rules=rules):
    entry_has_missing_data = has_missing_data(entry)
    applied_classes = []
    for rule in using_rules:
        passed_rule = True
        for part in rule["parts"]:
            if entry[part[0]] != part[1] or entry[part[0]] == None:
                passed_rule = False
        if passed_rule == True:
            applied_classes.append(rule["class"])
    return max_class(applied_classes)

# Function that tests the rules in the rule array against
# some training set

def test_tree(testing_set, using_rules=rules):
    if len(testing_set) == 0:
       return
    correct_count = 0
    for entry in testing_set:
        if entry["class"] == classify(entry, using_rules):
            correct_count += 1
    return round(100 *(correct_count / len(testing_set)))

def test_information_loss():
    pass

def prune():
    max_rule_length = -1
    for rule in rules:
        rule_length = len(rule["parts"])
        if rule_length > max_rule_length:
            print(rule["parts"])

if __name__ == '__main__':
    parse_args()
    parse_spec_file(args.spec)
    parse_data_file(args.dat)
    partition_sets()
    induce(training_set)
    if flags["prune_tree"]:
        prune()
    print("Classify on training => " + str(test_tree(training_set)))
    print("Classify on testing => " + str(test_tree(testing_set)))
    output_file.close()
